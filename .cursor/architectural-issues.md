# üö® Architectural Issues: MoneyControl Lock-In

## Critical Finding

**The agent is NOT general-purpose. It's heavily biased toward MoneyControl.**

---

## üìä Issue Analysis

### **MoneyControl-Specific Code Found:**

| File | Lines | Issue | Impact |
|------|-------|-------|--------|
| `context_extractor.py` | 36-58 | Hardcoded MoneyControl URL patterns | ‚ùå Fails for Bloomberg, Reuters, company sites |
| `context_extractor.py` | 66-80 | Weak regex for prompt extraction | ‚ö†Ô∏è Misses many company names |
| `navigator.py` | 69-95 | Dedicated MoneyControl function | ‚ùå Prioritizes MC logic, ignores others |
| `navigator.py` | 104-108 | MoneyControl tried FIRST | üî• **Critical bias** |
| `navigator.py` | 159-160 | MoneyControl special-casing | ‚ö†Ô∏è Different behavior per site |
| `navigator.py` | 192-200 | MoneyControl path filtering | ‚ö†Ô∏è Hardcoded logic |
| `graph.py` | 197-199 | MoneyControl listing skip | ‚ö†Ô∏è Hardcoded URL check |

**Total:** 23 MoneyControl mentions across 4 files

---

## üî• Critical Gaps: Missing LLM Calls

### **1. Context Extraction** (Currently Rule-Based)
**File:** `context_extractor.py` line 13  
**Current:** Regex pattern matching for MoneyControl URLs  
**Problem:**
```python
# Works
url = "moneycontrol.com/stockpricequote/personal-care/marico/M13"
‚Üí company: "Marico" ‚úÖ

# FAILS
url = "bloomberg.com/quote/MRCO:IN"
‚Üí company: None ‚ùå

url = "reuters.com/companies/MRCO.NS"
‚Üí company: None ‚ùå

url = "marico.com/investors/news"
‚Üí company: None ‚ùå
```

**Should Use LLM:**
```python
async def extract_context_with_llm(url: str, prompt: str) -> dict:
    """
    LLM analyzes URL structure + prompt to extract context.
    Works for ANY site, not just MoneyControl.
    """
    llm_prompt = f"""
    Extract company/entity and topic from:
    URL: {url}
    User Prompt: {prompt}
    
    Examples:
    - bloomberg.com/quote/AAPL:US + "latest news" ‚Üí Apple, stock news
    - reuters.com/markets/companies/TSLA.O ‚Üí Tesla, company updates
    - techcrunch.com + "AI startups" ‚Üí AI startups, tech news
    
    Return JSON: {{"company": "X", "topic": "Y", "is_specific": bool}}
    """
```

---

### **2. Listing URL Discovery** (Currently Hardcoded)
**File:** `navigator.py` line 101  
**Current:** MoneyControl patterns FIRST, then generic heuristics  
**Problem:**
```python
# MoneyControl
seed = "moneycontrol.com/stockpricequote/marico/M13"
‚Üí Constructs: "moneycontrol.com/news/tags/marico.html" ‚úÖ

# Bloomberg
seed = "bloomberg.com/quote/MRCO:IN"
‚Üí Generic heuristics look for links... maybe finds something? ‚ö†Ô∏è

# Company website
seed = "marico.com/investors"
‚Üí Generic heuristics likely fail ‚ùå
```

**Should Use LLM:**
```python
async def discover_listing_with_llm(seed_html: str, seed_url: str, context: dict) -> str:
    """
    LLM analyzes page structure to find best navigation target.
    Works for ANY site architecture.
    """
    llm_prompt = f"""
    Analyze this {context['company']} page to find news/press releases.
    
    Page URL: {seed_url}
    Links found: {top_20_links}
    
    Which link is most likely to have recent {context['company']} news?
    Consider: "News", "Press Releases", "Investors", "Media", etc.
    
    Return best URL or null if current page is already good.
    """
```

---

### **3. Article Link Filtering** (Currently Partially LLM)
**File:** `link_extractor.py` line 20  
**Current:** LLM filters links ‚úÖ (This one is actually good!)  
**Problem:** LLM gets heuristic-filtered links as input  
**Risk:** Heuristics might exclude valid articles

**Current Flow:**
```
Raw HTML ‚Üí Heuristic filter (hardcoded patterns) ‚Üí LLM filter ‚Üí Final links
                ‚Üë Problem: excludes non-standard URLs
```

**Should Be:**
```
Raw HTML ‚Üí Smart pre-filter (basic sanity) ‚Üí LLM filter ‚Üí Final links
                ‚Üë Minimal filtering, let LLM decide
```

---

## üåê Real-World Failure Examples

### **Example 1: Bloomberg**
```python
url = "https://www.bloomberg.com/quote/MRCO:IN"
prompt = "Summarize recent Marico news"

# Current behavior:
extract_context_from_url_and_prompt(url, prompt)
‚Üí {
    "company": None,  # ‚ùå Regex can't parse Bloomberg URLs
    "topic": "Summarize recent Marico news",  # Falls back to raw prompt
    "is_specific": False  # ‚ùå Wrong! User specified Marico
}

# Downstream impact:
# - Page analyzer doesn't know we're looking for Marico
# - Link extractor doesn't prioritize Marico-specific links
# - May extract generic market news instead
```

### **Example 2: Company Website**
```python
url = "https://marico.com/investors/press-releases"
prompt = "Latest updates"

# Current behavior:
extract_context_from_url_and_prompt(url, prompt)
‚Üí {
    "company": None,  # ‚ùå Not a MoneyControl pattern
    "topic": "Latest updates",  # Too vague
    "is_specific": False
}

# Downstream impact:
# - Doesn't recognize this is the official Marico site
# - May try to navigate away (bad!)
# - Treats as generic news, not company-specific
```

### **Example 3: Reuters**
```python
url = "https://www.reuters.com/companies/MRCO.NS"
prompt = "Q3 earnings summary"

# Current behavior:
extract_context_from_url_and_prompt(url, prompt)
‚Üí {
    "company": None,  # ‚ùå Reuters ticker format not recognized
    "topic": "Q3 earnings summary",
    "is_specific": False
}

# Downstream impact:
# - Doesn't know MRCO.NS = Marico
# - Can't filter for Marico-specific articles
# - May return general market news
```

---

## üí° Root Cause Analysis

### **Why This Happened:**

1. **Development was demo-driven**
   - Built for specific MoneyControl demo
   - Added hardcoded patterns that worked for that demo
   - Never generalized

2. **"Make it work" ‚Üí "Make it right" transition never happened**
   - Got the demo done ‚úÖ
   - Never refactored for generality ‚ùå

3. **Avoided LLM calls for speed/cost**
   - Context extraction is "free" with regex
   - But breaks for 90% of use cases

4. **Pattern accumulation**
   - Added MoneyControl pattern
   - Then another MoneyControl pattern
   - Then special-casing for MoneyControl
   - Never stepped back to see the forest

---

## üéØ Where LLMs SHOULD Be Used

### **Good Rule of Thumb:**
**Use LLM when the logic is "intelligent interpretation", not "deterministic transformation"**

| Task | Current | Should Be | Why |
|------|---------|-----------|-----|
| Extract company from URL | Rule-based | ü§ñ LLM | URLs vary by site, need interpretation |
| Parse date "2 hours ago" | Rule-based | ‚úÖ Rule-based | Deterministic transformation |
| Decide if page needs navigation | ü§ñ LLM | ‚úÖ LLM | Requires understanding page structure |
| Filter article links | ü§ñ LLM | ‚úÖ LLM | Requires relevance judgment |
| Validate content length | Rule-based | ‚úÖ Rule-based | Simple threshold |
| Detect paywall | Rule-based | ‚úÖ Rule-based | Pattern matching is fine |
| Categorize summary | ü§ñ LLM | ‚úÖ LLM | Semantic task |
| Normalize URL | Rule-based | ‚úÖ Rule-based | String manipulation |

### **Specific Gaps:**

#### **Gap 1: Context Extraction** üî• CRITICAL
**Current:** Rule-based (MoneyControl-only)  
**Should Be:** LLM-based (universal)  
**Reason:** Every website structures URLs differently

#### **Gap 2: Company/Entity Recognition** üî• CRITICAL
**Current:** Regex patterns  
**Should Be:** LLM with entity recognition  
**Reason:** "MRCO.NS", "Marico Ltd", "Marico India" all mean the same thing

#### **Gap 3: Seed Page Classification** üî∂ IMPORTANT
**Current:** Basic heuristics  
**Should Be:** LLM classification  
**Reason:** Is this a stock page, news page, or company homepage?

#### **Gap 4: Source Reliability Assessment** ‚ö†Ô∏è NICE-TO-HAVE
**Current:** None  
**Should Be:** LLM scoring  
**Reason:** Official company site > Bloomberg > random blog

---

## üîß Proposed Fixes

### **Priority 1: Generalize Context Extraction** üî•

**Replace:** `context_extractor.py` with LLM-based extraction

```python
# NEW: agent/context_extractor_llm.py

async def extract_context_with_llm(
    url: str, 
    prompt: str,
    llm: ChatOpenAI
) -> dict:
    """
    Universal context extraction using LLM.
    Works for ANY website, not just MoneyControl.
    """
    
    # Parse URL for basic info
    parsed = urlparse(url)
    domain = parsed.netloc
    path = parsed.path
    
    extraction_prompt = f"""You are analyzing a web page to understand what the user is researching.

URL: {url}
Domain: {domain}
Path: {path}
User Prompt: {prompt}

TASK: Extract the following:
1. COMPANY/ENTITY: What specific company, organization, or entity is this about?
   - Extract from URL structure, domain, path components
   - Examples: 
     * "bloomberg.com/quote/AAPL:US" ‚Üí Apple
     * "reuters.com/companies/TSLA.O" ‚Üí Tesla
     * "moneycontrol.com/...marico..." ‚Üí Marico
     * "marico.com" ‚Üí Marico (official site)
     * "techcrunch.com" ‚Üí None (generic tech news)

2. TOPIC: What is the user researching?
   - If specific company: "[Company] news" or "[Company] [specific aspect]"
   - If generic: extract from prompt

3. SOURCE_TYPE: What kind of website is this?
   - official_company_site (investors.apple.com)
   - financial_news (bloomberg.com, reuters.com)
   - stock_aggregator (moneycontrol.com, yahoo finance)
   - tech_news (techcrunch.com)
   - generic_news
   - other

4. IS_SPECIFIC: Is this about a specific entity (true) or general topic (false)?

Respond ONLY with valid JSON:
{{
  "company": "Marico" or null,
  "topic": "Marico news" or "AI startups",
  "source_type": "financial_news",
  "is_specific": true,
  "confidence": "high" | "medium" | "low",
  "reasoning": "One sentence explanation"
}}
"""
    
    try:
        response = await llm.ainvoke(extraction_prompt)
        result = json.loads(response.content.strip())
        
        logger.info(f"LLM context extraction: {result}")
        return result
        
    except Exception as e:
        logger.error(f"LLM context extraction failed: {e}")
        # Fallback to basic extraction
        return {
            "company": None,
            "topic": prompt,
            "source_type": "unknown",
            "is_specific": False,
            "confidence": "low",
            "reasoning": "Fallback due to LLM failure"
        }
```

**Benefits:**
- ‚úÖ Works for Bloomberg, Reuters, Yahoo Finance, etc.
- ‚úÖ Handles company websites (marico.com, apple.com)
- ‚úÖ Recognizes stock tickers (MRCO.NS, AAPL, TSLA.O)
- ‚úÖ Understands domain ‚Üí entity mapping
- ‚úÖ One model to rule them all

**Cost:** ~$0.0005 per request (gpt-4o-mini)

---

### **Priority 2: Remove MoneyControl-Specific Code** üßπ

**Files to Update:**

#### **1. navigator.py**
```python
# REMOVE: Lines 69-95 (_moneycontrol_listing_from_seed)
# REMOVE: Lines 104-108 (MoneyControl priority)
# REMOVE: Lines 159-160 (MoneyControl special-casing)
# REMOVE: Lines 192-200 (MoneyControl path filtering)

# REPLACE WITH: Generic LLM-based navigation discovery
async def discover_listing_url_universal(
    seed_url: str,
    seed_html: str,
    context: dict,
    llm: ChatOpenAI
) -> Optional[str]:
    """
    Universal listing discovery using page analysis.
    No site-specific logic.
    """
    # Extract top navigation links
    soup = BeautifulSoup(seed_html, "html.parser")
    nav_links = []
    for a in soup.find_all("a", href=True)[:30]:
        nav_links.append({
            "url": urljoin(seed_url, a["href"]),
            "text": a.get_text(strip=True)
        })
    
    # Ask LLM to identify best navigation target
    prompt = f"""Find the best link for {context['topic']} articles.

Current page: {seed_url}
Available links: {json.dumps(nav_links)}

Which link leads to news/articles about {context['company'] or context['topic']}?
Look for: "News", "Press Releases", "Media", "Investors", "Blog", etc.

Return the best URL, or null if current page is already good.
"""
    # ... LLM call
```

#### **2. graph.py**
```python
# REMOVE: Lines 197-199 (MoneyControl listing skip)

# REPLACE WITH: Generic listing detection
if await is_listing_page(url, html):  # LLM-based
    _emit(state, {"event": "fetch:skip", "reason": "listing_page"})
    continue
```

#### **3. context_extractor.py**
```python
# REMOVE: Lines 36-58 (MoneyControl patterns)
# KEEP: Lines 66-80 (prompt regex) as fallback
# ADD: LLM-based extraction as primary method
```

---

### **Priority 3: Add Missing LLM Intelligence**

#### **New LLM Call: Source Reliability** (Optional)
```python
async def assess_source_reliability(url: str, domain: str) -> dict:
    """
    Score source credibility.
    Official site > Major news > Unknown blog
    """
    prompt = f"""Rate the reliability of this news source:
    Domain: {domain}
    URL: {url}
    
    Categories:
    - official_company (100% reliable, primary source)
    - major_financial_news (95% reliable - Bloomberg, Reuters, WSJ)
    - reputable_news (85% reliable - TechCrunch, Verge)
    - aggregator (70% reliable - MoneyControl, Yahoo)
    - unknown (50% reliable)
    
    Return: {{"reliability": "major_financial_news", "score": 95}}
    """
```

---

## üìä Comparison: Before vs After

### **Before (Current System)**

```python
# Bloomberg URL
url = "bloomberg.com/quote/MRCO:IN"

Context Extraction ‚Üí ‚ùå FAILS (no MoneyControl pattern)
  ‚Üí company: None
  ‚Üí Treats as generic news

Page Analysis ‚Üí ‚ö†Ô∏è CONFUSED
  ‚Üí Doesn't know we want Marico
  ‚Üí May navigate to wrong section

Link Extraction ‚Üí ‚ö†Ô∏è PARTIAL
  ‚Üí LLM tries its best with vague context
  ‚Üí May include non-Marico articles

Result: 50% success rate
```

### **After (LLM-Based System)**

```python
# Bloomberg URL
url = "bloomberg.com/quote/MRCO:IN"

Context Extraction (LLM) ‚Üí ‚úÖ SUCCESS
  ‚Üí company: "Marico"
  ‚Üí source_type: "financial_news"
  ‚Üí Recognizes MRCO:IN ticker

Page Analysis ‚Üí ‚úÖ INFORMED
  ‚Üí Knows to look for Marico content
  ‚Üí Navigates to Marico-specific section

Link Extraction ‚Üí ‚úÖ PRECISE
  ‚Üí LLM filters with full context
  ‚Üí Only Marico articles selected

Result: 95% success rate
```

---

## üéØ Implementation Plan

### **Phase 1: Critical Fixes (2-3 days)**
- [ ] Create `context_extractor_llm.py` with universal extraction
- [ ] Update `graph.py` to use LLM context extraction
- [ ] Test with 5 different sources:
  - [ ] MoneyControl (should still work)
  - [ ] Bloomberg
  - [ ] Reuters
  - [ ] Company website (marico.com)
  - [ ] Yahoo Finance

### **Phase 2: Cleanup (1-2 days)**
- [ ] Remove MoneyControl-specific code from `navigator.py`
- [ ] Remove MoneyControl hardcoding from `graph.py`
- [ ] Replace with generic LLM-based logic
- [ ] Test all 5 sources again

### **Phase 3: Enhancement (Optional, 1 day)**
- [ ] Add source reliability scoring
- [ ] Add entity normalization (MRCO.NS = Marico = Marico Ltd)
- [ ] Add multi-language support

---

## üí∞ Cost Impact

### **Current System:**
- 3 LLM calls per request
- Cost: ~$0.018

### **After Adding Context LLM:**
- 4 LLM calls per request
- Cost: ~$0.019 (+$0.001)

**Verdict:** +5% cost for 10x generalization ‚Üí **Worth it!**

---

## ‚úÖ Success Criteria

System should handle ALL of these without code changes:

- [ ] MoneyControl stock page
- [ ] Bloomberg quote page
- [ ] Reuters company page
- [ ] Yahoo Finance quote
- [ ] Official company website (marico.com/investors)
- [ ] TechCrunch article page
- [ ] Generic news site
- [ ] Stock ticker in prompt (MRCO.NS, AAPL, etc.)
- [ ] Company name variations (Marico, Marico Ltd, Marico India)

---

## üö® Severity Assessment

**Current State:** üî¥ **CRITICAL ARCHITECTURE FLAW**

- Works great for MoneyControl demos
- Fails silently for most other sources
- Users think it's general-purpose, but it's not
- Technical debt is high (23 MC-specific mentions)

**Recommended Action:** **Fix before production launch**

This is not a "nice-to-have" - it's a **blocker for general availability**.

---

*Analysis Date: October 30, 2025*

